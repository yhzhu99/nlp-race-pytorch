{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_from_disk(\"datasets_hf/race_high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "sampled_index = random.sample(range(len(dataset['train'])), 1000)\n",
    "len(sampled_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(sample, mode=\"train\"):\n",
    "    prompt: str\n",
    "    if mode == \"train\":\n",
    "        prompt = 'Article: ' + sample['article'].replace(\"\\n\\n\", \"\\n\") + '\\n' + \\\n",
    "                'Question: ' + sample['question'].replace(\"\\n\\n\", \"\\n\") + '\\n' + \\\n",
    "                'Options: ' + ' | '.join([f'({chr(65+i)}) {opt}' for i, opt in enumerate(sample['options'])]) + '\\n' + \\\n",
    "                'Answer: ' + sample['answer']\n",
    "    elif mode == \"test\":\n",
    "        prompt = 'Please directly give the answer with a single A or B or C or D. The output should one single letter!' + '\\n' + \\\n",
    "                'Article: ' + sample['article'].replace(\"\\n\\n\", \"\\n\") + '\\n' + \\\n",
    "                'Question: ' + sample['question'].replace(\"\\n\\n\", \"\\n\") + '\\n' + \\\n",
    "                'Options: ' + ' | '.join([f'({chr(65+i)}) {opt}' for i, opt in enumerate(sample['options'])]) + '\\n' + \\\n",
    "                'Answer is ? '\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('prompts/race-train-1000.txt', 'w') as ftest:\n",
    "#     for idx in sampled_index:\n",
    "#         ftest.write(format_prompt(dataset['train'][idx], \"train\"))\n",
    "#         ftest.write(\"\\n\\n\\n\")\n",
    "\n",
    "out = {}\n",
    "for idx in range(len(dataset['test'])):\n",
    "    cur = dataset['test'][idx]\n",
    "    out[cur['example_id']] = {\n",
    "        'prompt': format_prompt(cur, \"test\"),\n",
    "        'answer': cur['answer'],\n",
    "    }\n",
    "\n",
    "pd.to_pickle(out, 'prompts/testset_high.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_gen(prompt):\n",
    "    return ' \\n A\\n'\n",
    "\n",
    "for x in out:\n",
    "    ans = answer_gen(out[x]['prompt'])\n",
    "    print(f\"{x}\\t{ans.strip()}\\t{out[x]['answer']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
